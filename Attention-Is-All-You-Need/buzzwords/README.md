# Buzzwords Index

This folder contains detailed explanations of key terms referenced in the Attention Is All You Need materials.

Files:
1. `attention.md`
2. `self-attention.md`
3. `scaled-dot-product-attention.md`
4. `multi-head-attention.md`
5. `sequence-to-sequence-modeling.md`
6. `encoder-decoder-architecture.md`
7. `positional-encoding.md`
8. `parallelization.md`
9. `residual-connection.md`
10. `layer-normalization.md`
11. `dropout.md`
12. `regularization.md`
13. `embedding.md`
14. `feed-forward-neural-network.md`
15. `multi-layer-perceptron.md`
16. `optimization-algorithm.md`
17. `rotary-positional-embedding-rope.md`
